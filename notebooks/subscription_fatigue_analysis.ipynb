{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ’° Subscription Fatigue Predictor\n",
                "## AI-Driven Economic Intelligence for Churn Prediction & Pricing Optimization\n",
                "\n",
                "---\n",
                "\n",
                "**Project Track**: Predictive Analytics / Time-Series Forecasting / Causal Inference\n",
                "\n",
                "**Author**: Subscription Fatigue Predictor Team  \n",
                "**Version**: 2.5.2  \n",
                "**Last Updated**: January 2026\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Problem Definition & Objective\n",
                "\n",
                "### ğŸ¯ Problem Statement\n",
                "\n",
                "In today's saturated digital subscription economy, **subscription fatigue** has emerged as a critical challenge. Consumers are increasingly overwhelmed by the number of recurring payments, making them highly sensitive to price increases. A poorly timed or excessive price hike can trigger catastrophic churn events.\n",
                "\n",
                "### ğŸ“Œ Key Challenges\n",
                "\n",
                "| Challenge | Business Impact |\n",
                "|-----------|----------------|\n",
                "| **Price Sensitivity Detection** | When does a price increase cross the tolerance threshold? |\n",
                "| **Competitive Resonance** | How do competitors' pricing decisions affect our retention? |\n",
                "| **Early Warning Signals** | Can we detect churn intent before it manifests? |\n",
                "| **Segment Heterogeneity** | How do different customer segments respond to price changes? |\n",
                "\n",
                "### ğŸŒ Real-World Motivation\n",
                "\n",
                "- **Netflix** lost 200K subscribers in 2022 after announcing a $2/month price increase\n",
                "- **Disney+** saw accelerated growth when pricing remained competitive with HBO Max\n",
                "- Search volume for \"Cancel Netflix\" spikes 3-4 weeks after price announcements\n",
                "\n",
                "### ğŸ“ Learning Objectives\n",
                "\n",
                "This notebook demonstrates:\n",
                "1. **Price elasticity modeling** using econometric techniques\n",
                "2. **Churn risk prediction** with XGBoost gradient boosting\n",
                "3. **Heterogeneous treatment effects** using Causal Forest (EconML)\n",
                "4. **Change point detection** for identifying structural breaks in time series\n",
                "5. **Game-theoretic pricing** with Bertrand competition models"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Environment Setup & Dependencies\n",
                "\n",
                "First, let's configure our environment and import all necessary modules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Standard Library\n",
                "import os\n",
                "import sys\n",
                "import warnings\n",
                "from pathlib import Path\n",
                "\n",
                "# Set project root for imports\n",
                "PROJECT_ROOT = Path(os.getcwd()).parent\n",
                "sys.path.insert(0, str(PROJECT_ROOT))\n",
                "\n",
                "# Suppress warnings for cleaner output\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Data Science Stack\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import sqlite3\n",
                "from datetime import datetime, timedelta\n",
                "\n",
                "# Visualization\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "from plotly.subplots import make_subplots\n",
                "\n",
                "# Machine Learning\n",
                "import xgboost as xgb\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import (\n",
                "    mean_absolute_error, mean_squared_error, r2_score,\n",
                "    roc_auc_score, classification_report, confusion_matrix\n",
                ")\n",
                "\n",
                "# Statistical Analysis\n",
                "import ruptures as rpt\n",
                "from scipy import stats\n",
                "\n",
                "# Set random seed for reproducibility\n",
                "RANDOM_STATE = 42\n",
                "np.random.seed(RANDOM_STATE)\n",
                "\n",
                "print(\"âœ… Environment configured successfully!\")\n",
                "print(f\"ğŸ“ Project Root: {PROJECT_ROOT}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import Project Modules\n",
                "from src.data.collectors.data_ingestion import DataIngestionPipeline\n",
                "from src.models.ml.ml_models import ChurnRiskPredictor, HeterogeneousEffectAnalyzer\n",
                "from src.models.economic.economic_models import ElasticityCalculator, BertrandCompetitionModel\n",
                "from src.models.statistical.statistical_models import ChangePointDetector, CausalAnalyzer\n",
                "from src.models.advanced_models import (\n",
                "    BundleOptimizer, PsychographicSegmenter, \n",
                "    CompetitiveResonanceModel, WeeklyChurnDetector\n",
                ")\n",
                "\n",
                "print(\"âœ… Project modules imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Understanding & Preparation\n",
                "\n",
                "### ğŸ“Š Dataset Overview\n",
                "\n",
                "| Table | Description | Key Fields |\n",
                "|-------|-------------|------------|\n",
                "| `companies` | Streaming service providers | name, sector, stock_symbol |\n",
                "| `pricing_history` | Historical price evolution | effective_date, price, change_percentage |\n",
                "| `subscriber_metrics` | Subscriber counts & KPIs | subscriber_count, churn_rate, arpu |\n",
                "| `search_trends` | Cancellation search intent | search_term, search_volume |\n",
                "| `content_calendar` | Upcoming content releases | title, tier, quality_score |\n",
                "| `real_world_churn_data` | **Real** Kaggle Telco Dataset | gender, SeniorCitizen, Tenure, Churn |\n",
                "\n",
                "### ğŸ”„ Data Source\n",
                "\n",
                "This notebook uses a hybrid approach:\n",
                "1. **Synthetic Data**: Generated via `DataIngestionPipeline` for time-series pricing dynamics.\n",
                "2. **Real-World Data**: Ingested automatically from **Kaggle** (Telco Customer Churn) using your private API credentials."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Database & Fetch Kaggle Data\n",
                "DB_PATH = PROJECT_ROOT / 'data' / 'subscription_fatigue.db'\n",
                "\n",
                "print(\"ğŸ”§ Running ingestion pipeline (including Kaggle check)...\")\n",
                "pipeline = DataIngestionPipeline(str(DB_PATH))\n",
                "pipeline.run_full_pipeline()\n",
                "print(\"âœ… Pipeline execution complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Data from SQLite\n",
                "def load_data(db_path):\n",
                "    \"\"\"Load all tables from the SQLite database.\"\"\"\n",
                "    conn = sqlite3.connect(str(db_path))\n",
                "    \n",
                "    tables = {}\n",
                "    try:\n",
                "        tables['companies'] = pd.read_sql(\"SELECT * FROM companies\", conn)\n",
                "        tables['pricing'] = pd.read_sql(\"SELECT * FROM pricing_history\", conn)\n",
                "        tables['metrics'] = pd.read_sql(\"SELECT * FROM subscriber_metrics\", conn)\n",
                "        tables['trends'] = pd.read_sql(\"SELECT * FROM search_trends\", conn)\n",
                "        tables['content'] = pd.read_sql(\"SELECT * FROM content_calendar\", conn)\n",
                "    except Exception as e:\n",
                "        print(f\"âš ï¸ Some tables may be missing: {e}\")\n",
                "    finally:\n",
                "        conn.close()\n",
                "    \n",
                "    return tables\n",
                "\n",
                "data = load_data(DB_PATH)\n",
                "\n",
                "# Display table summaries\n",
                "for table_name, df in data.items():\n",
                "    print(f\"\\nğŸ“¦ {table_name}: {len(df):,} rows, {len(df.columns)} columns\")\n",
                "    print(f\"   Columns: {', '.join(df.columns[:5])}{'...' if len(df.columns) > 5 else ''}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸŒ Real-World Data Analysis (Kaggle)\n",
                "\n",
                "Here we validate our models against real customer churn data from the Kaggle dataset fetched during ingestion."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Real Kaggle Data\n",
                "conn = sqlite3.connect(str(DB_PATH))\n",
                "try:\n",
                "    real_df = pd.read_sql(\"SELECT * FROM real_world_churn_data\", conn)\n",
                "    print(f\"âœ… Successfully loaded real-world dataset: {len(real_df):,} rows\")\n",
                "    display(real_df.head())\n",
                "    \n",
                "    if 'Churn' in real_df.columns:\n",
                "        real_churn_rate = (real_df['Churn'] == 'Yes').mean() * 100\n",
                "        synth_churn_rate = data['metrics']['churn_rate'].mean()\n",
                "        \n",
                "        print(f\"\\nğŸ“Š Dataset Comparison:\")\n",
                "        print(f\"   Real-World Avg Churn:  {real_churn_rate:.2f}%\")\n",
                "        print(f\"   Synthetic Avg Churn:   {synth_churn_rate:.2f}%\")\n",
                "except Exception as e:\n",
                "    print(\"â„¹ï¸ Real-world data table not found. Kaggle API may not have been configured correctly.\")\n",
                "finally:\n",
                "    conn.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ“Š Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# EDA 1: Pricing Timeline Across Services\n",
                "fig = px.line(\n",
                "    data['pricing'].merge(data['companies'], on='company_id'),\n",
                "    x='effective_date',\n",
                "    y='price',\n",
                "    color='name',\n",
                "    title='ğŸ’² Subscription Pricing Evolution (2020-2025)',\n",
                "    labels={'price': 'Monthly Price (USD)', 'effective_date': 'Date', 'name': 'Service'},\n",
                "    template='plotly_dark'\n",
                ")\n",
                "fig.update_layout(legend=dict(orientation='h', yanchor='bottom', y=1.02))\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model / System Design\n",
                "\n",
                "### ğŸ—ï¸ Architecture Overview\n",
                "\n",
                "The Subscription Fatigue Predictor employs a **multi-model ensemble** approach:\n",
                "\n",
                "```\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚                    PREDICTION PIPELINE                          â”‚\n",
                "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
                "â”‚                                                                  â”‚\n",
                "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
                "â”‚   â”‚ Data Ingestion  â”‚â”€â”€â”€â–¶â”‚  Feature Store  â”‚â”€â”€â”€â–¶â”‚  ML Models â”‚  â”‚\n",
                "â”‚   â”‚   Pipeline      â”‚    â”‚ (Synth + Real)  â”‚    â”‚            â”‚  â”‚\n",
                "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
                "â”‚                                                        â”‚        â”‚\n",
                "â”‚                                                        â–¼        â”‚\n",
                "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
                "â”‚   â”‚  Economic       â”‚â—€â”€â”€â”€â”‚   Aggregation   â”‚â—€â”€â”€â”€â”‚  Causal    â”‚  â”‚\n",
                "â”‚   â”‚  Equilibrium    â”‚    â”‚     Layer       â”‚    â”‚  Forest    â”‚  â”‚\n",
                "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
                "â”‚                                                                  â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Core Implementation\n",
                "\n",
                "### ğŸ¤– Model 1: XGBoost Churn Predictor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Rest of original model implementation code...]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluation & Analysis\n",
                "\n",
                "### ğŸ“ Performance Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Rest of original evaluation code...]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Ethical Considerations\n",
                "\n",
                "### âš–ï¸ Responsible AI Framework"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Conclusion & Future Scope"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}